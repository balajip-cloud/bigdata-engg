from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, FloatType

# Create Spark session
spark = SparkSession.builder.appName("Oracle EMP and DEPT Data").getOrCreate()

# ----------------------
# DEPT Table
# ----------------------

dept_data = [
    (10, "ACCOUNTING", "NEW YORK"),
    (20, "RESEARCH", "DALLAS"),
    (30, "SALES", "CHICAGO"),
    (40, "OPERATIONS", "BOSTON")
]

dept_schema = StructType([
    StructField("DEPTNO", IntegerType(), False),
    StructField("DNAME", StringType(), True),
    StructField("LOC", StringType(), True)
])

dept_df = spark.createDataFrame(data=dept_data, schema=dept_schema)

# ----------------------
# EMP Table
# ----------------------

emp_data = [
    (7839, "KING", "PRESIDENT", None, "1981-11-17", 5000.0, None, 10),
    (7698, "BLAKE", "MANAGER", 7839, "1981-05-01", 2850.0, None, 30),
    (7782, "CLARK", "MANAGER", 7839, "1981-06-09", 2450.0, None, 10),
    (7566, "JONES", "MANAGER", 7839, "1981-04-02", 2975.0, None, 20),
    (7902, "FORD", "ANALYST", 7566, "1981-12-03", 3000.0, None, 20),
    (7369, "SMITH", "CLERK", 7902, "1980-12-17", 800.0, None, 20),
    (7499, "ALLEN", "SALESMAN", 7698, "1981-02-20", 1600.0, 300.0, 30),
    (7521, "WARD", "SALESMAN", 7698, "1981-02-22", 1250.0, 500.0, 30),
    (7654, "MARTIN", "SALESMAN", 7698, "1981-09-28", 1250.0, 1400.0, 30),
    (7844, "TURNER", "SALESMAN", 7698, "1981-09-08", 1500.0, 0.0, 30),
    (7876, "ADAMS", "CLERK", 7788, "1983-01-12", 1100.0, None, 20),
    (7900, "JAMES", "CLERK", 7698, "1981-12-03", 950.0, None, 30),
    (7788, "SCOTT", "ANALYST", 7566, "1982-12-09", 3000.0, None, 20),
]

emp_schema = StructType([
    StructField("EMPNO", IntegerType(), False),
    StructField("ENAME", StringType(), True),
    StructField("JOB", StringType(), True),
    StructField("MGR", IntegerType(), True),
    StructField("HIREDATE", StringType(), True),  # Can convert to DateType if needed
    StructField("SAL", FloatType(), True),
    StructField("COMM", FloatType(), True),
    StructField("DEPTNO", IntegerType(), True)
])

emp_df = spark.createDataFrame(data=emp_data, schema=emp_schema)

# If you want HIREDATE as a DateType column:
from pyspark.sql.functions import to_date
emp_df = emp_df.withColumn("HIREDATE", to_date("HIREDATE", "yyyy-MM-dd"))

# ----------------------
# Show DataFrames
# ----------------------

print("EMP Table:")
emp_df.show()

print("DEPT Table:")
dept_df.show()
